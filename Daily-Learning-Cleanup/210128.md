## 강의 내용 정리

-   **Pandas III**
-   **Pandas IV**
-   **확률론**

##### Pandas III

1.  Groupby Method  
    `groupby` 메서드는 SQL의 명령어와 흡사한 기능을 하는 메서드이다. 조건에 맞는 데이터를 선별하여 split하고, 일정한 연산을 apply하고, combine하여 결과값을 반환한다.  
    `df_ob.grouby(['column1', 'column2']).func()`과 같은 형태로 쓸 수 있다. 먼저, `column1`과 `2`이 기준이 되어 같은 값인 데이터가 묶인다. 이후 `func()`에 의해 연산이 일어난 결과가 조합되어 반환된다.  

2.  Hierachical Index  
    위와 같이 2개 이상의 기준으로 groupby를 수행하게 되면, 결과물은 2개 이상의 `Multi-index`를 갖게 된다. Multi-index의 Series나 DataFrame에 대해서는 `unstack`이나 `reset_index`와 같은 메서드를 사용해 직관적으로 데이터를 이해할 수 있다.  
    Multi-index는 `level`이 있으며, 이를 기준으로 연산과 변경 등의 작업을 수행할 수 있다.  

3.  Grouped DataFrame  
    `gorupby` 메서드에 의해 split된 상태를 추출할 수 있다. `grouped = df.groupby('column')`과 같이 일정 변수에 해당 값을 받을 수 있으며, `grouped`는 `column`에 해당하는 값을 `key`로 갖고, `dataframe`을 `value`로 갖는 형태의 dict 객체가 된다.  
    해당 객체에 `get_group`과 같은 메서드를 통해 `value`에 접근할 수 있다.  

4.  Grouped Object Operation  
    이렇게 추출된 객체에는 세가지 유형의 apply가 가능하다.  
    *  Aggregation : 요약된 통계정보  추출
    *  Transformation : 해당 정보를 변환
    *  Filtration : 특정 정보를 제거하여 변환  

    Aggregation은 다음과 같다. `grouped.agg(func)` 혹은 `grouped.agg([func1, func2])`와 같은 형태로 사용할 수 있으며, 하나의 Series별로 연산이 수행되고 한 셀에 값이 출력된다.  
    Transformation은 요약된 정보가 아니라, 개별 데이터의 변환을 지원한다. `grouped.transform(func)`와 같이 사용할 수 있으며, 하나의 Series별로 연산이 수행되고, 각 셀에 값이 출력된다.
    Filter는 특정 조건을 통과하는 데이터만을 추출할 수 있다. `grouped.filter(condition_func)`와 같이 사용할 수 있으며, 하나의 Series전체를 대상으로 함수를 씌워 조건에 통과하는지 확인하고, 통과한 값만 출력된다.

##### Pandas IV

1.  dateutil  
    시간 형태의 데이터이나, `dtype`이 `object`인 `column`을 실제 `datetype`으로 변경할 수 있다. 예시는 다음과 같다.  
    ```python
    # dateutil example
    import dateutil
    df['time'] = df['time'].apply(dateutil.parser.parse, dayfirst=True)
    ```

2.  Aggregation Example  
    `agg`메서드는 다음과 같이도 사용할 수 있다. 적용할 column을 key로, 적용할 function을 value로 전달하여 값을 출력할 수 있다. function은 `list`나 `str` type으로도 전달할 수 있다.  
    ```python
    df.groupby(['month', 'item']).agg({
        'duration' : sum,
        'network_type' : 'count',
        'date' : ['first', min, 'nunique']
    })
    ```
    이렇게 출력되는 dataframe의 `column name`은 전달된 함수로만 표현되기 때문에, `column.rename` 혹은 `add_prefix` 메서드를 통해 명시적으로 변경할수도 있다.

3.  Pivot Table & Crosstab  
    Index는 groupby와 동일하고, column에 추가로 labling하여, value에 aggregation한 값을 표현하는 메서드이다. 지정된 index와 column의 값에 따라 value가 요약되어 표현된다.  
    ``` python
    # pivot_table example
    df.pivot_table(
        ['value'],
        index = [df['month'], df['item']],
        columns = df['network'],
        aggfunc = 'sum',
        fillvalue = 0
    )
    ```

    `crosstab`은 두 column사이의 교차빈도와 같은 값을 구할때 사용한다.  
    ``` python
    # crosstab example
    pd.crosstab(
        index = df['user'],
        columns = df['title'],
        values = df['rating'],
        aggfunc='first'
    )
    ```

4.  Merge   
    `merge` 메서드는 SQL의 `join`과 유사한 사용법을 가지고 있다. `pd.merge(df_a, df_b, on='id')`와 같이 사용할 수 있고, 이 경우에는 inner join이 발생한다.  
    dataframe간의 column 이름이 다른 경우에는 `left_on`과 `right_on`에 해당하는 column name을 전달하면 된다.  
    outer join을 원하는 경우에는 `how`에 `left`, `right`, `outer`와 같은 값을 전달하여 수행할 수 있다.  
    동일한 column이 있던 경우에는 중복되는 column이 생길 수 있기 때문에, 이를 확인하고 정리해줘야 한다.

5.  Concat  
    `concat` 메서드는 두 dataframe을 합치는데 사용할 수 있다. `pd.concat([df_a, df_b])`와 같이 사용할 수 있고, 이 경우에는 위 아래로 합쳐지게 된다. `df_a.append(df_b)`도 동일한 결과가 출력된다. 이와 같은 방법은 두 dataframe의 column의 형태가 동일할 때 사용할 수 있다.  
    좌우로 데이터 프레임을 합치려고 한다면, `axis=1`로 지정하면 되며, 이 때 기준은 index가 된다.

6.  Persistence  
    Data loading 시 DB와 연결해서 수행할 수 있다. local에서 사용할 수 있는 `sqlite3`와 연결해서 사용하는 예시는 다음과 같다.  
    ```python
    # db connect example
    import sqlite3

    conn = sqlite3.connect('path/data.db')
    cur = conn.cursor()
    cur.execute('select * from table;')
    result = cur.fetchall()
    result

    # query and dataframe example
    df_table_a = pd.read_sql_query('select * from table_a;', conn)
    df_table_b = pd.read_sql_query('select * from table_b;', conn)
    print(type(df_table_a), type(df_table_b))  # dataframe
    ```

##### 확률론

1.  확률론이란?  
    딥러닝의 학습 방법은 확률론에 기반을 두고 있다. 기계학습의 손실함수는 데이터 공간을 통계적으로 해석하여 유도하게 된다. 예측이 틀리는 것을 최소화하도록 데이터를 학습하는 원리를 가진다.  
    기계학습에서 사용되는 모든 손실함수는 `실제 데이터의 분포`와 `모델 예측하는 분포`의 차이를 줄이려고 하는 것이다. 이 두 대상을 측정하는 방법은 통계학을 기반으로 한다.

2.  확률분포란?  
    확률 분포는 데이터 공간에 위치하는 데이터들을 이해하기 위한 일종의 초상화이다. 실제 데이터가 생성되는 확률분포 $\mathcal{D}$를 알 수 없고, 데이터만을 가지고 확률분포를 파악할 수는 없다. 그렇기 때문에, 기계학습을 통해 이 확률분포에 근사하는 함수를 찾고자 한다.  

3.  확률변수란?  
    확률변수란, 데이터 공간 상에서 관측 가능한 데이터이다. 변수가 1개인 지도학습을 상정했을때, 데이터 공간은 $x \times y$가 된다. 확률변수는 이 공간상에서 관측되는 원소들이다. 확률변수는 함수에 의해 해석된다. 이 함수는 임의로 데이터 공간상에서 관측하게 되는 함수이다.  
    데이터 공간상에서 데이터를 추출할 때 확률변수를 사용하게 되며, 이렇게 추출된 데이터의 분포 $\mathscr{D}$가 실제 분포 $\mathcal{D}$에 근사하는 것을 목표로 한다.

4.  이산확률변수와 연속확률변수란?  
    데이터 공간으로부터 확률변수에 의해 추출된 데이터는 분포를 가지며, 확률분포 $\mathscr{D}$라고 할 수 있다. 이 확률분포 $\mathscr{D}$에 따라 이산형과 연속형이 구분된다. 이는 데이터 공간 $x \times y$와 무관하며, 오직 $\mathscr{D}$에 의해 결정된다.

5.  확률 모델링  
    이산형 확률변수는 확률변수가 가질 수 있는 경우의 수를 모두 고려하여 확률을 더해 모델링한다. 식은 다음과 같다. $\mathbb{P}(X \in A) = \Sigma_{x \in A}{P(X=x)}$  
    연속형 확률변수는 데이터 공간에 정의된 확률변수의 밀도의 적분을 통해 모델링한다. 식은 다음과 같다. $\mathbb{P}(X \in A) = \int_A {P(\mathbf{x})d\mathbf{x}}$

6.  결합분포란?  
    결합분포는 주어진 데이터로부터 확률변수$\mathbf{x}$와 $y$를 통해 얻은 것으로 $\mathscr{D}$를 의미한다. 즉, 결합분포 $P(\mathbf{x}, y)$는 $\mathscr{D}$를 모델링하는 것이다.

7.  주변확률분포란?  
    $P(\mathbf{x})$는 입력 $\mathbf{x}$에 대한 주변확률분포로 $y$에 대한 정보를 주지 않는다. 오직 $\mathbf{x}$에 대해서만 그려진 확률분포이다. 이는 식으로 설명될 수 있다.  
    $\mathscr{D}$가 이산형일 때, $P(\mathbf{x}) = \sum_y{P(\mathbf{x},y)}$  
    $\mathscr{D}$가 연속형일 때, $P(\mathbf{x}) = \int_y{P(\mathbf{x},y)dy}$

8.  조건부 확률분포란?  
    $P(\mathbf{x}|y)$는 $y$가 특정 값으로 주어졌을 때 $\mathbf{x}$에 대한 확률분포를 의미한다. 이는 데이터 공간에서 입력 $\mathbf{x}$와 출력$y$ 사이의 관계를 모델링한다.  
    반대로, 조건부확률 $P(y|x)$는 입력변수 $\mathbf{x}$에 대해 정답이 $y$일 확률을 의미한다.  
    로지스틱 회귀에서 사용했던 선형모델과 softmax 함수의 결합은 데이터에서 추출된 패턴을 기반으로 확률을 해석하는데 사용된 것이다. 분류 문제에서 $softmax(\mathbf{W}\phi+\mathbf{b})$는 데이터 $\mathbf{x}$로부터 추출된 특징패턴 $\phi(\mathbf{x})$과 가중치 행렬 $\mathbf{W}$을 통해 조건부 확률 $P(y|\mathbf{x})$을 계산하는 것이다.  

9.  조건부 기대값이란?
    회귀문제의 경우에는 특정 $y$값이 될 확률을 구하는 것이 아니기 때문에, 조건부 기대값을 추정한다.  
    조건부 기대값인 $\mathbb{E}[y|\mathbf{x}]$은 함수 $f(\mathbf{x})$와 일치하는데, 이 함수는 $\mathbb{E}||y-f(\mathbf{x})||_2$를 최소화하는 함수이다.  
    조건부 기대값은 밀도함수인 조건부 확률분포에서 y에 대해 적분한 값이 된다.

10. 기대값이란?  
    기대값은 데이터를 대표하는 통계량이며, 다른 통계적 수치를 계산하는데 사용된다. 수식은 다음과 같다.   
    $P(\mathbf{x})$가 이산형일 때, $\mathbb{E}[f(\mathbf{x})] = \sum{f(\mathbf{x})P(\mathbf{x})}$  
    $P(\mathbf{x})$가 연속형일 때, $\mathbb{E}[f(\mathbf{x})] = \int{f(\mathbf{x})P(\mathbf{x})}$

11. 딥러닝과 특징패턴  
    딥러닝은 주어진 데이터 $\mathbf{x}$로부터 다층 신경망을 통해 특징패턴 $\phi$를 추출한다. 이때, 특징패턴을 학습하기 위해 어떤 손실함수를 사용할지는 기계학습의 문제와 모델에 의해 결정되는 것이다.  

12. 몬테카를로 샘플링  
    기계학습의 많은 문제들은 확률분포를 명시적으로 모를 때가 대부분이다. 이 때, 데이터를 이용해 기대값을 계산하는 방법으로 몬테카를로 샘플링을 이용할 수 있다.  
    특정 데이터에 대해서 독립추출을 한다면, **대수의 법칙**에 따라 이들의 기대값은 실제 데이터 분포의 기대값에 수렴한다는 것이다.  
    이는 이산형과 연속형에 무관하게 사용 가능하나, 샘플링하는 데이터의 크기가 작은 경우 참값에서 멀어질 수 있다.

---

## Peer Sesion

-   **강의내용 토의**
-   **Dacon 토의**
-   **Peer Session Event**

##### 강의내용 토의  

1.  확률분포 등에 대한 정보 공유
2.  수학 기초에 대한 정보 공유

##### Dacon 토의

1.  Dacon 참가 및 팀 결성
2.  관련 논문 및 정보 공유

##### Peer Session Event

1.  참가 및 조 소개
2.  다른 조의 아이디어 벤치마킹