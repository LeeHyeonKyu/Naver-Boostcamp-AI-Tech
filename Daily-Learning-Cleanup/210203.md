## 강의 내용 정리

-   **Basic CNN**
-   **Modern CNN**
-   **Computer Vision Applications**
-   **Dog Breed Dataset**
-   **Own Dataset**

##### Basic CNN

1.  Convolution이란?  
    Convolution Operation은 원래 Signal Processing에서 사용되던 개념이다. 이는 두 함수를 특정 방식으로 섞어주는 연산자의 역할을 했다. 이 개념을 Neural Network에 적용한 것이 CNN이다. Image Data에 많이 사용되며, 2D Convolution Operation을 표현하면 다음과 같다.  
    $$[I*K](i,j) = \sum_m\sum_n{I(m,n)K(i-m,j-n)}$$  
    동일한 Kernel이 Input Data 위에서 이동하는 형태로, 이는 Filter와 Image로 대체하여 생각할 수 있다. 이 Filter의 Parameter에 따라 출력되는 Feature Map은 기존의 Image와 다른 특성을 가질 수 있게 된다.

2.  RGB Image Convolution  
    RGB Scale의 Image는 공간적 의미를 갖는 두 개의 Dimention과, 색상을 표현하는 Channel을 갖는다. 이 Channel은 기본적으로 3의 값을 갖는다.  
    2D Convolution을 수행할 때에는 Input Date인 Tensor와 Filter의 Channel을 동일하게 맞춰야 한다. 그래야 Channel에 해당하는 Dimention은 고정된 상태에서 2D를 이동하며 연산을 할 수 있기 때문이다. Filter를 통해 출력된 Feature Map의 채널은 Filter의 갯수에 따라 결정된다. 

3.  Basic CNN  
    기본적인 CNN은 3개의 구성요소를 가진다.  
    1.  Convolution Layer : Convolution Operating을 통해 Feature Map을 얻는 Layers
    2.  Pooling Layer : Feature Map의 특정 정보만 전달하는 Layers
    3.  Fully Connected Layer : Feature Map을 Flat하게 만들고, 원하는 Output 차원에 맞게 조정하는 Dense Layers  

4.  Stride and Padding  
    Stride는 보폭을 의미하며, Filter가 Data 위에서 매번 이동하는 양을 결정한다.  
    Padding은 Image의 가장자리에 특정 값을 채워넣음으로써 Filter가 가장자리에도 도달할 수 있도록 한다.  
    Stride와 Padding을 적절하게 조절하면, Feature Map이 Input Data와 동일한 크기를 가지도록 하는 등의 조정이 가능하다.  

5.  Convolution Artithmetic  
    Neural Network의 Parameter가 일정 이상 많아지게 되면, 성능이 떨어지는 것은 일반적으로 잘 알려져 있는 사실이다. 그만큼 Parameter의 수를 줄이는 것이 Deep Learning의 과제 중 하나이다.  
    Convolution 연산은 동일한 Kernel(=Filter)가 재사용 되는 형태로, FCL에 비해 매우 적은 Parameter를 가질 수 있다. 이를 통해 현재 CNN은 매우 좋은 성능을 내고 있다. CNN의 발전은 Parameter를 줄이면서 동시에 더 깊은 구조와 좋은 성능을 내는 방향으로 이어지고 있다.  
    CNN에서는 Filter와 이를 통해 출력된 Feature Map의 Channel을 알고 있다면, 사용된 Parameter의 갯수를 구할 수 있다. 유명한 AlexNet의 구조를 살펴보더라도, 다섯 층에 걸쳐 사용된 Convolution Layer의 Parameter가, FCL의 Parameter에 비해 수천배 적은 것을 볼 수 있다.  

##### Modern CNN  

1.  ILSVRC  
    Imagenet Large Scale Visual Recognition Challenge의 약어로, Machine Learning의 큰 대회이다. 2012년 AlexNet이 처음으로 Neural Network 구조를 통해 우승을 차지했고, 이를 통해 패러다임이 변화하여 오늘날까지 Neural Network 구조가 우승을 차지하고 있다. 2015년에는 사람보다 오차율이 낮은 모델까지 구현되었다.  

2.  AlexNet  
    AlexNet은 5개의 Convolution Layer와 3개의 Dense Layer를 통해 구현했다. 지금은 당연하게 여겨지는 개념일 수 있는데, 이는 그만큼 AlexNet이 좋은 방법에 대한 기준을 제시한 것과 동일하다. 이 안에 들어간 핵심은 다음과 같다.  
    *   ReLU : 비선형 함수로 ReLU를 사용했다. 이는 다른 활성함수의 Vanishing Grad 문제를 해결할 수 있었다.
    *   GPU : GPU를 활용해 학습시켜 효율성을 높였다.
    *   Data Augmentation : Train Data를 다양하게 만들고 양을 늘렸다.
    *   Drop Out : Drop Out을 통해 모델을 강건하게 만들었다.

3.  VGGNet  
    VGGNet은 오직 3x3 형태의 Filter만을 사용했다. 이는 Parameter를 줄이는데 매우 효과적인 방법이다.  
    5x5 Filter를 한 번 사용한 Layer 구조와 3x3 Filter를 두 Layer로 쌓은 구조가 있을 때, 이 둘은 동일한 Receptive Field를 갖는다. 하지만, 3x3 Filter를 두 Layer로 쌓은 구조가 훨씬 적은 Parameter를 사용하게 된다.  

4.  GoogLeNet  
    GoogLeNet은 1x1 Filter를 사용해 획기적으로 Parameter의 숫자를 줄였다. 이외에도 Inception Block을 활용해 Feature Map을 Concate하거나, Network-in-Network 구조로 모델을 구성한 점도 있으나, 더 중요한 Point는 1x1 Filter의 사용이다.  
    128개의 Chanel을 갖는 Tensor에 3x3 Filter를 적용해 128 Channel의 Feature Map을 출력한다고 했을때, 이를 바로 사용하는 것 대신 중간에 1x1 Filter를 넣는 것이다. 1x1 Filter를 넣음으로써 Receptive Field는 동일하면서 Parameter의 수는 매우 획기적으로 줄어드는 효과를 거뒀다.

5.  ResNet  
    일반적으로 30 Layers 이상의 모델은 오히려 15 Layers 정도의 모델보다 일반화 성능이 낮았다. 허나 ResNet은 Skip Connection 구조를 도입하여 훨씬 더 깊은 모델을 구성해도 성능이 좋아지는 효과를 거뒀다.  
    이외에도 Bottleneck Architecture를 이용해 Parameter의 수를 줄였으며, Batch Normalization을 하는 등의 기법을 사용했다.

6.  DenseNet  
    DenseNet은 ResNet의 Skip Connection 구조를 사용하면서, 더하는 것 대신 Concatnate시켜 데이터가 섞이지 않도록 했다.  
    이는 차원이 기하급수적으로 커지는 경향이 있었기 때문에 이를 줄이는 Transition Block을 구성했다.  

##### Computer Vision Applications  

1.  Computer Vision Methods  
    Computer Vision에는 한 장의 Image를 분류하는 Classification외에도 여러 분야가 존재한다. 특히 Semantic Segmentation과 Object Detection은 오늘날 곳곳에서 사용되고 있는 분야이다.

2.  Semantic Segmentation  
    Classification과 다르게, Image 내에서 분류를 수행해야 한다. 그렇기 때문에 때로는 Dense Classification 혹은 Per-Fixel Classification이라고 불리기도 한다. 자율주행 등에 활용되고 있으며 매우 중요한 문제이자 분야이다.

3.  Fully Convolutional Network  
    기존의 CNN 구조로는 위 문제를 풀 수 없다. 최종으로 출력되는 Label에 각 Fixel에 대한 위치 값이 없기 때문이다. 이를 해결하기 위해 기존에 사용했던 FCL 구조(Dense Layer)를 사용하지 않고 모든 Network를 Convolutionalization시킨다.  
    예를 들어, Convolution Layer에서 출력된 Feature Map이 4x4x16의 Tensor라고 한다. 이를 10개의 Label로 출력하고자 한다. 이 상황에서 Convolutionalize는 다음과 같이 이루어진다. 4x4x16의 Filter를 10개 사용하여, 1x1x10의 Tensor를 Label로 사용하는 것이다.  
    위의 방법은 FCL을 사용하는 것과 Parameter의 갯수에서는 차이가 전혀 없다. 하지만, 최종 출력된 Tensor에는 각 Fixel의 위치정보와 최종적으로 구분하고자 하는 Class의 정보가 들어가기 때문에 해당 문제를 푸는 방법으로 사용할 수 있는 것이다.  

4.  Deconvoultion  
    위와 같은 방법으로 위치정보와 Class의 정보를 가질 수는 있지만, 최종적으로 출력되는 Label의 해상도는 Input Image에 비해 작을 수 밖에 없다. 이를 맞춰주기 위해 사용하는 방법이 Deconvolution이다.  
    Feature Map에 적절하게 Padding을 줘서, 해당 값들을 통해 원래의 Image 크기로 늘려나가는 방식이다. 이 때에도 Convolution 연산이 일어난다.
    엄밀히 말하면, Deconvolution은 Convolution 연산을 역으로 수행하는 것은 아니다. 이미 값이 합쳐진 Feature Map에서 원래의 값을 찾아 복원하는 것은 아니기 때문이다.

5.  Object Detection  
    Sementic Segmentation이 Fixel 별로 Classfication 하는 것이라면, 이는 Object의 위치를 찾고 이를 구별해내는 문제이다.  

6.  R-CNN  
    R-CNN은 위 문제를 풀기 위해 먼제 제시된 방법으로 동작은 다음과 같이 이루어진다.  
    1.  주어진 Image Data에 2000개의 Bounding Box를 만든다.
    2.  Bounding Box 별로 Image를 잘라 특정 크기로 일정하게 만든다.
    3.  자른 Image를 AlexNet에 통과시켜, Object의 여부를 결정한다.
    4.  이 Data를 SVM에 전달해 Class를 결정한다.

7.  SPPNet  
    R-CNN은 2000개의 Bounding Box가 순차적으로 CNN구조를 통과하기 때문에 속도가 매우 느렸다. 이를 해결하기 위해 Bounding Box의 위치를 Batch 형태로 저장하고, CNN에 한번만 통과시키는 방법을 사용했다.

8.  Fast R-CNN  
    SPPNet과 유사한 아이디어로 구성되었으며, ROI Pooling을 사용하는 등의 기법이 추가되었다. 이 모델이 시사하는 바는, 모든 구조를 Neural Network로 구성했다는 점이다.

9.  Faster R-CNN  
    Bounding Box를 구성하는 Region Proposal 마저 임의의 방법을 사용하지 않고, Neural Network를 사용하는 방법이다. 위의 구조에서 Region Proposal Network가 추가 된 개념이다. 이 Network에서는 오직 Object가 있는지 없는지만 확인하여 해당 데이터를 뒤로 전달한다.  
    Reigion Proposal Network는 9개의 템플릿과, 4개의 템플릿 조절 기능, 해당 Box가 유의미한지 결정하는 값으로 총 9*(4+2)=54개의 채널을 가진 Tensor를 결과값으로 출력한다. 해당 Tensor가 어떤 Class에 속하는지는 뒤의 Network에서 수행한다.

10. YOLO  
    R-CNN과 다르게, Bounding Box처리와 Classification을 동시에 수행한다. 매우 빠른 속도를 자랑하며, 현재는 Real Time의 속도를 자랑하고 있다. 동작 순서는 다음과 같다.  
    1.  Image를 S*S Grid로 나눈다.
    2.  Grid의 중앙이 어떤 Object인지 분류한다.
    3.  Grid에 속하는 Box가 유의미한지 판단한다.

    YOLO에서 최종적으로 출력되는 Tensor는 S*S*(B*5+C)이다. S는 Grid의 형태를 의미하고, B는 Bounding Box의 값(x좌표, y좌표, 너비, 높이, 유의미 여부)을 의미하고, C는 해당 Box의 Class값을 갖게 된다.