{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"make_bone.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNMIuyGQZa3E9s1maDwe0Y+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"LLkESZ5qu3bt"},"source":["## 1. 사전환경 구성"]},{"cell_type":"code","metadata":{"id":"qA1m1yLRyKk5","executionInfo":{"status":"ok","timestamp":1612951645485,"user_tz":-540,"elapsed":1526,"user":{"displayName":"이현규","photoUrl":"","userId":"11926500847670507435"}}},"source":["# import librarys\r\n","from google.colab import output\r\n","from google.colab import drive\r\n","from pathlib import Path\r\n","import os\r\n","import pandas as pd\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import cv2\r\n","from tqdm import tqdm\r\n","import imutils\r\n","import zipfile\r\n","from PIL import Image\r\n","from sklearn.model_selection import KFold\r\n","import random\r\n","\r\n","import torch\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","import torchvision.models as models\r\n","import torchvision.transforms as T\r\n","from torch.utils.data import DataLoader, Dataset"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fs3L4I0owKC7","executionInfo":{"status":"ok","timestamp":1612951647846,"user_tz":-540,"elapsed":3852,"user":{"displayName":"이현규","photoUrl":"","userId":"11926500847670507435"}},"outputId":"69314408-5bc3-45e3-a099-6717c094f855"},"source":["# mount google drive\r\n","drive.mount('/content/drive')"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Sa2zrXGtgWlu","executionInfo":{"status":"ok","timestamp":1612951647851,"user_tz":-540,"elapsed":3852,"user":{"displayName":"이현규","photoUrl":"","userId":"11926500847670507435"}}},"source":["# set random seed\r\n","seed = 42\r\n","random.seed(seed)\r\n","np.random.seed(seed)\r\n","torch.manual_seed(seed)\r\n","torch.cuda.manual_seed_all(seed)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aYPZ1zLWwpv7","executionInfo":{"status":"ok","timestamp":1612951647853,"user_tz":-540,"elapsed":3843,"user":{"displayName":"이현규","photoUrl":"","userId":"11926500847670507435"}},"outputId":"cd724dc6-8f21-4852-c3da-bb84482c76ed"},"source":["# set path\r\n","os.chdir('/content/drive/MyDrive/dirty_mnist')\r\n","ROOT_PATH = Path(os.getcwd())\r\n","print(f'ROOT_PATH : {ROOT_PATH}')"],"execution_count":19,"outputs":[{"output_type":"stream","text":["ROOT_PATH : /content/drive/MyDrive/dirty_mnist\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LRTIQyNIzfJX","executionInfo":{"status":"ok","timestamp":1612951647856,"user_tz":-540,"elapsed":3836,"user":{"displayName":"이현규","photoUrl":"","userId":"11926500847670507435"}},"outputId":"8d931dff-4507-418d-8c98-3ad73fc314e1"},"source":["# set device\r\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n","print(f'device : {device}')"],"execution_count":20,"outputs":[{"output_type":"stream","text":["device : cuda:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"het8EOp6CUFc"},"source":["## 2. 데이터셋 구성"]},{"cell_type":"code","metadata":{"id":"SKi3rFBIzptv","executionInfo":{"status":"ok","timestamp":1612951647858,"user_tz":-540,"elapsed":3833,"user":{"displayName":"이현규","photoUrl":"","userId":"11926500847670507435"}}},"source":["# define ToTensor\r\n","class ToTensor(object) :\r\n","    '''\r\n","    numpy array를 torch tensor로 변환\r\n","    변환하고자 하는 array를 전달인자로 하여 호출 (np.ndarray)\r\n","    image의 차원을 tensor 형식으로 변경 (C x H x W)\r\n","    '''\r\n","    \r\n","    def __call__(self, sample) :\r\n","        image, label = sample['image'], sample['label']\r\n","        image = image.transpose((2, 0, 1))\r\n","        return {'image': torch.FloatTensor(image),\r\n","                'label': torch.FloatTensor(label)}"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"X9K6klRhGlQw","executionInfo":{"status":"ok","timestamp":1612951647862,"user_tz":-540,"elapsed":3833,"user":{"displayName":"이현규","photoUrl":"","userId":"11926500847670507435"}}},"source":["# create transform pipline object\r\n","train_transforms = T.Compose([ToTensor()])\r\n","test_transforms = T.Compose([ToTensor()])"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"m17x-Qx3Gsxa","executionInfo":{"status":"ok","timestamp":1612951647864,"user_tz":-540,"elapsed":3831,"user":{"displayName":"이현규","photoUrl":"","userId":"11926500847670507435"}}},"source":["# define DatasetMNIST\r\n","class DatasetMNIST(torch.utils.data.Dataset) :\r\n","    '''\r\n","    DataLoader에 의해 호출 될 Dataset\r\n","    dif_path : image가 위치한 directory path\r\n","    meta_df : train data의 answers\r\n","    __getitem__.index : DataLoader가 입력\r\n","    __getitem__ return : dict type object (key = ['image', 'label'])\r\n","    '''\r\n","    \r\n","    def __init__(self,\r\n","                 dir_path,\r\n","                 meta_df,\r\n","                 transforms=None,\r\n","                 augmentations=None\r\n","                 ) :\r\n","\r\n","        self.dir_path = dir_path\r\n","        self.meta_df = meta_df\r\n","        self.transforms = transforms\r\n","        self.augmentations = augmentations\r\n","    \r\n","    def __len__(self) :\r\n","        return len(self.meta_df)\r\n","    \r\n","    def __getitem__(self, index) :\r\n","        image = cv2.imread(self.dir_path+\\\r\n","                           str(self.meta_df.iloc[index,0]).zfill(5)+'.png',\r\n","                           cv2.IMREAD_GRAYSCALE)\r\n","        image = (image/255).astype('float')[..., np.newaxis]\r\n","        label = self.meta_df.iloc[index, 1:].values.astype('float')\r\n","        sample = {'image': image, 'label': label}\r\n","        if self.transforms :\r\n","            sample = self.transforms(sample)\r\n","        \r\n","        return sample"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"MH5w3Yqchuqz","executionInfo":{"status":"ok","timestamp":1612951647867,"user_tz":-540,"elapsed":3819,"user":{"displayName":"이현규","photoUrl":"","userId":"11926500847670507435"}},"outputId":"d867ed3d-989b-46f2-8202-623970b76f58"},"source":["# load data labels\r\n","mnist_answers = pd.read_csv(ROOT_PATH/'data/dirty_mnist_2nd_answer.csv')\r\n","mnist_answers.head()"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>e</th>\n","      <th>f</th>\n","      <th>g</th>\n","      <th>h</th>\n","      <th>i</th>\n","      <th>j</th>\n","      <th>k</th>\n","      <th>l</th>\n","      <th>m</th>\n","      <th>n</th>\n","      <th>o</th>\n","      <th>p</th>\n","      <th>q</th>\n","      <th>r</th>\n","      <th>s</th>\n","      <th>t</th>\n","      <th>u</th>\n","      <th>v</th>\n","      <th>w</th>\n","      <th>x</th>\n","      <th>y</th>\n","      <th>z</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   index  a  b  c  d  e  f  g  h  i  j  k  ...  o  p  q  r  s  t  u  v  w  x  y  z\n","0      0  1  1  0  1  0  1  0  0  0  0  1  ...  1  1  0  1  1  0  1  0  0  1  1  1\n","1      1  1  0  0  1  0  1  0  1  0  1  0  ...  0  1  0  1  0  1  0  0  0  0  1  1\n","2      2  0  0  0  0  0  0  0  0  1  1  0  ...  0  1  0  0  1  1  1  0  1  1  1  0\n","3      3  0  0  1  0  0  0  1  1  0  0  0  ...  0  1  1  0  1  1  0  1  1  0  1  0\n","4      4  0  1  0  1  0  1  0  1  1  0  1  ...  0  1  0  1  0  0  0  1  0  1  0  0\n","\n","[5 rows x 27 columns]"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"xzMQQxt-MIPO"},"source":["## 3. 모델 구성"]},{"cell_type":"code","metadata":{"id":"3yqKknLdLpPj","executionInfo":{"status":"ok","timestamp":1612951647872,"user_tz":-540,"elapsed":3818,"user":{"displayName":"이현규","photoUrl":"","userId":"11926500847670507435"}}},"source":["# define MultiLabelResnet18\r\n","class MultiLabelResnet18(nn.Module) :\r\n","    '''\r\n","    Pretrained ResNet18 사용\r\n","    Input과 Output Dimension을 맞추기 위해 layer 추가\r\n","    최종 출력은 softmax가 아닌 sigmoid 사용\r\n","    '''\r\n","\r\n","    def __init__(self) :\r\n","        super(MultiLabelResnet18, self).__init__()\r\n","        self.conv2d = nn.Conv2d(1, 3, 3, stride=1)\r\n","        self.resnet = models.resnet18(pretrained=True)\r\n","        self.FC = nn.Linear(1000, 26)\r\n","    \r\n","    def forward(self, x) :\r\n","        x = F.relu(self.conv2d(x))\r\n","        x = F.relu(self.resnet(x))\r\n","        x = torch.sigmoid(self.FC(x))\r\n","        return x"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"HPMWHMxKdgp7","executionInfo":{"status":"ok","timestamp":1612951647873,"user_tz":-540,"elapsed":3815,"user":{"displayName":"이현규","photoUrl":"","userId":"11926500847670507435"}}},"source":["# define new_model\r\n","def new_model(model=MultiLabelResnet18, lr=0.001, step_size=5, gamma=0.75) :\r\n","    model = model()\r\n","    model.to(device)\r\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\r\n","    lr_scheduler = torch.optim.lr_scheduler.StepLR(\r\n","        optimizer, step_size=step_size, gamma=gamma)\r\n","    \r\n","    return model, optimizer, lr_scheduler"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"heX30UhIcJmK"},"source":["## 4. 모델 학습 및 평가"]},{"cell_type":"code","metadata":{"id":"BSln9fjBaS35","executionInfo":{"status":"ok","timestamp":1612951647874,"user_tz":-540,"elapsed":3811,"user":{"displayName":"이현규","photoUrl":"","userId":"11926500847670507435"}}},"source":["# set training schedule\r\n","n_fold = 3\r\n","n_epochs = 3\r\n","train_batch_size = 128\r\n","valid_batch_size = 32"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"PxcTbzsaixhQ","executionInfo":{"status":"ok","timestamp":1612951647875,"user_tz":-540,"elapsed":3807,"user":{"displayName":"이현규","photoUrl":"","userId":"11926500847670507435"}}},"source":["# initialize objects\r\n","kfold = KFold(n_splits=n_fold, shuffle=True, random_state=seed)\r\n","best_models = []\r\n","train_data_path = str(ROOT_PATH)+'/data/train_data/'"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"GG8dpxLietJH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bcc00d3f-063b-40a9-e114-06ae65ed2038"},"source":["# loop in kfold\r\n","for fold_count, (train_index, valid_index) in enumerate(kfold.split(mnist_answers), 1) :\r\n","    print(f'[fold: {fold_count}]')\r\n","    torch.cuda.empty_cache()\r\n","    \r\n","    # create data iterator \r\n","    train_answer = mnist_answers.iloc[train_index]\r\n","    valid_answer = mnist_answers.iloc[valid_index]\r\n","\r\n","    train_dataset = DatasetMNIST(\r\n","        dir_path = train_data_path,\r\n","        meta_df = train_answer,\r\n","        transforms = train_transforms\r\n","    )\r\n","    valid_dataset = DatasetMNIST(\r\n","        dir_path = train_data_path,\r\n","        meta_df = valid_answer,\r\n","        transforms = train_transforms\r\n","    )\r\n","    \r\n","    train_data_loader = DataLoader(\r\n","        train_dataset,\r\n","        batch_size = train_batch_size,\r\n","        shuffle = False,\r\n","        num_workers = 3\r\n","    )\r\n","    valid_data_loader = DataLoader(\r\n","        valid_dataset,\r\n","        batch_size = valid_batch_size,\r\n","        shuffle = False,\r\n","        num_workers = 3\r\n","    )\r\n","\r\n","    # create new model, optimizer, etc\r\n","    model, optimizer, lr_scheduler = new_model()\r\n","    criterion = torch.nn.BCELoss()\r\n","\r\n","    valid_acc_max = 0\r\n","    for epoch in range(n_epochs) :\r\n","        \r\n","        # start to training\r\n","        train_acc_list = []\r\n","        with tqdm(train_data_loader,\r\n","                  total=train_data_loader.__len__(),\r\n","                  unit=\"batch\"\r\n","                  ) as train_bar :\r\n","            for sample in train_bar :\r\n","                train_bar.set_description(f\"Train Epoch {epoch}\")\r\n","                images, labels = sample['image'], sample['label']\r\n","                images = images.to(device)\r\n","                labels = labels.to(device)\r\n","\r\n","                optimizer.zero_grad()\r\n","                model.train()\r\n","                with torch.set_grad_enabled(True) :\r\n","                    probs = model.forward(images)\r\n","                    loss_out = criterion(probs, labels)\r\n","                    loss_out.backward()\r\n","                    optimizer.step()\r\n","\r\n","                probs = probs.cpu().detach().numpy()\r\n","                labels = labels.cpu().detach().numpy()\r\n","                preds = probs > 0.5\r\n","                batch_acc = (labels == preds).mean()\r\n","                train_acc_list.append(batch_acc)\r\n","                train_acc = np.mean(train_acc_list)\r\n","                train_bar.set_postfix(train_loss = loss_out.item(),\r\n","                                        train_acc = train_acc)\r\n","        \r\n","        # start to validation\r\n","        valid_acc_list = []\r\n","        with tqdm(valid_data_loader,\r\n","                  total=valid_data_loader.__len__(),\r\n","                  unit=\"batch\"\r\n","                  ) as valid_bar :\r\n","            for sample in valid_bar :\r\n","                valid_bar.set_description(f\"Valid Epoch {epoch}\")\r\n","                images, labels = sample['image'], sample['label']\r\n","                images = images.to(device)\r\n","                labels = labels.to(device)\r\n","\r\n","                optimizer.zero_grad()\r\n","                model.eval()\r\n","                with torch.no_grad() :\r\n","                    probs = model.forward(images)\r\n","                    loss_out = criterion(probs, labels)\r\n","                    loss_out.backward()\r\n","                    optimizer.step()\r\n","\r\n","                probs = probs.cpu().detach().numpy()\r\n","                labels = labels.cpu().detach().numpy()\r\n","                preds = probs > 0.5\r\n","                batch_acc = (labels == preds).mean()\r\n","                valid_acc_list.append(batch_acc)\r\n","                valid_acc = np.mean(valid_acc_list)\r\n","                valid_bar.set_postfix(valid_loss = loss_out.item(),\r\n","                                        valid_acc = valid_acc)\r\n","\r\n","        # learning rate scheduling\r\n","        lr_scheduler.step()\r\n","\r\n","        # save good models\r\n","        if valid_acc_max < valid_acc :\r\n","            valid_acc_max = valid_acc\r\n","            best_model = model\r\n","            MODEL = 'resnet18'\r\n","            model_path = str(ROOT_PATH)+'/model'\r\n","            torch.save(best_model, f'{model_path}{fold_index}_{MODEL}_{valid_loss.item():2.4f}_epoch_{epoch}.pth')\r\n","    \r\n","    best_models.append(best_model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[fold: 1]\n"],"name":"stdout"},{"output_type":"stream","text":["Train Epoch 0:  31%|███       | 81/261 [04:57<22:28,  7.49s/batch, train_acc=0.541, train_loss=0.682]"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"WaTxPVkPICZQ"},"source":["## 5. 테스트 환경 구성"]},{"cell_type":"code","metadata":{"id":"I39xL962rLGR"},"source":["# set test dataset\r\n","test_data_path = str(ROOT_PATH)+'/data/test_data'\r\n","test_batch_size =128\r\n","\r\n","sample_submission = pd.read_csv(ROOT_PATH/'data/sample_submission.csv')\r\n","test_dataset = DatasetMNIST(\r\n","    dir_path = test_data_path,\r\n","    meta_df = sample_submission,\r\n","    transforms = test_transforms\r\n",")\r\n","test_data_loader = DataLoader(\r\n","    test_dataset,\r\n","    batch_size = test_batch_size,\r\n","    shuffle = False,\r\n","    num_workers = 3,\r\n","    drop_last = False\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KE3rF-urLTYN"},"source":["# initialize objects\r\n","predictions_list = []\r\n","prediction_df = pd.read_csv(ROOT_PATH/'data/sample_submission.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zOPPnjJHQ3o-"},"source":["## 6. 테스트 수행"]},{"cell_type":"code","metadata":{"id":"xDox4iY9MsCX"},"source":["# loop in best models\r\n","for model in best_models :\r\n","    prediction_array = np.zeros([prediction_df.shape[0], \r\n","                                 prediction_df.shape[1]-1])\r\n","    # inference about test dataset\r\n","    for idx, sample in enumerate(test_data_loader) :\r\n","        with torch.no_grad() :\r\n","            model.eval()\r\n","            images = sample['image']\r\n","            images = images.to(device)\r\n","            probs = model(images)\r\n","            probs = probs.cpu().detach().numpy()\r\n","            preds = (probs > 0.5)\r\n","            \r\n","            batch_index = test_batch_size * idx\r\n","            prediction_array[batch_index : batch_index + images.shape[0], : ] = preds.astype(int)\r\n","    \r\n","    # save every model's prediction\r\n","    predictions_list.append(prediction_array[...,np.newaxis])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rVXtX85xQ13t"},"source":["## 7. 앙상블 및 제출파일 생성"]},{"cell_type":"code","metadata":{"id":"5GefWNRtQBx-"},"source":["# ensemble\r\n","predictions_array = np.concatenate(prdictions_list, axis = 2)\r\n","predictions_mean = predictions_array.mean(axis = 2)\r\n","predictions_mean = (predictions_mean > 0.5) * 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nMHAQl6wRAiU"},"source":["# save result file\r\n","file_name = str(model_path)+f'/{MODEL}_result.csv'\r\n","\r\n","prediction_df.iloc[:, 1:] =  predictions_mean\r\n","predcition_df.to_csv(file_name, index = False)\r\n","\r\n","print('Done')"],"execution_count":null,"outputs":[]}]}